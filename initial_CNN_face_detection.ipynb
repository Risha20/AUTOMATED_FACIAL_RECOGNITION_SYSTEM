{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xcMOSs3XQCQc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.datasets import fetch_lfw_people\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the LFW dataset\n",
        "lfw_dataset = fetch_lfw_people(min_faces_per_person=50, resize=0.4)\n",
        "X = lfw_dataset.data\n",
        "y = lfw_dataset.target\n",
        "target_names = lfw_dataset.target_names\n",
        "print(X)\n",
        "print(\"______________________\")\n",
        "print(y)\n",
        "print(\"______________________\")\n",
        "print(target_names)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnAwFRM2QFfI",
        "outputId": "eccfb7fc-2739-494a-ce2f-b7ccda2ab815"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.31764707 0.35555556 0.45228758 ... 0.42222223 0.5921569  0.49019608]\n",
            " [0.1385621  0.27320263 0.33464053 ... 0.23529412 0.3267974  0.45490196]\n",
            " [0.33594772 0.21830066 0.22745098 ... 0.6928105  0.32156864 0.303268  ]\n",
            " ...\n",
            " [0.19346406 0.24705882 0.34248367 ... 0.7346406  0.6640523  0.6117647 ]\n",
            " [0.530719   0.62614375 0.6653595  ... 0.9163399  0.8928105  0.8862745 ]\n",
            " [0.11633987 0.10196079 0.1267974  ... 0.13333334 0.13725491 0.2535948 ]]\n",
            "______________________\n",
            "[11  4  2 ...  3 11  5]\n",
            "______________________\n",
            "['Ariel Sharon' 'Colin Powell' 'Donald Rumsfeld' 'George W Bush'\n",
            " 'Gerhard Schroeder' 'Hugo Chavez' 'Jacques Chirac' 'Jean Chretien'\n",
            " 'John Ashcroft' 'Junichiro Koizumi' 'Serena Williams' 'Tony Blair']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess the images\n",
        "X = X.reshape((X.shape[0], 50, 37))  # Reshape to (num_samples, height, width)\n",
        "print(\"before:---------------\")\n",
        "print(X)\n",
        "X = np.array([cv2.normalize(img, None, 0, 255, cv2.NORM_MINMAX) for img in X])  # Normalize pixel values\n",
        "print(\"after:------------------------\")\n",
        "print(X)\n",
        "print(X.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrdOMieUQIaE",
        "outputId": "532a0f3e-c3a5-4d7d-8a57-312be8e541ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "before:---------------\n",
            "[[[0.31764707 0.35555556 0.45228758 ... 0.20522876 0.24444444 0.30588236]\n",
            "  [0.34640524 0.3764706  0.39869282 ... 0.18954249 0.17777778 0.27973858]\n",
            "  [0.36601308 0.37254903 0.3254902  ... 0.24183007 0.17908497 0.21960784]\n",
            "  ...\n",
            "  [0.19084968 0.18300654 0.17908497 ... 0.7241831  0.5124183  0.3281046 ]\n",
            "  [0.1882353  0.18431373 0.18039216 ... 0.6013072  0.5633987  0.38039216]\n",
            "  [0.18692811 0.18562092 0.18039216 ... 0.42222223 0.5921569  0.49019608]]\n",
            "\n",
            " [[0.1385621  0.27320263 0.33464053 ... 0.24705882 0.16993465 0.1633987 ]\n",
            "  [0.1764706  0.3137255  0.33464053 ... 0.30849674 0.22091503 0.20653595]\n",
            "  [0.20784314 0.3281046  0.33071896 ... 0.36732027 0.24183007 0.22091503]\n",
            "  ...\n",
            "  [0.02745098 0.23137255 0.53464055 ... 0.8718955  0.8156863  0.7764706 ]\n",
            "  [0.02614379 0.24183007 0.54640526 ... 0.4640523  0.475817   0.48235297]\n",
            "  [0.02091503 0.2535948  0.54901963 ... 0.23529412 0.3267974  0.45490196]]\n",
            "\n",
            " [[0.33594772 0.21830066 0.22745098 ... 0.39346406 0.37908497 0.38169935]\n",
            "  [0.27058825 0.2509804  0.22875817 ... 0.37908497 0.37777779 0.38431373]\n",
            "  [0.24313726 0.22745098 0.23529412 ... 0.38431373 0.37254903 0.3764706 ]\n",
            "  ...\n",
            "  [0.4392157  0.42222223 0.42745098 ... 0.6562092  0.55947715 0.49542484]\n",
            "  [0.43921575 0.4405229  0.4470589  ... 0.6836602  0.5411765  0.49019608]\n",
            "  [0.44836605 0.4496732  0.45228758 ... 0.6928105  0.32156864 0.303268  ]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0.19346406 0.24705882 0.34248367 ... 0.5882353  0.5947712  0.5647059 ]\n",
            "  [0.22875817 0.32287583 0.39084968 ... 0.58300656 0.56078434 0.55947715]\n",
            "  [0.23006536 0.351634   0.37124184 ... 0.5882353  0.53464055 0.53464055]\n",
            "  ...\n",
            "  [0.23660131 0.23921569 0.24313726 ... 0.5542484  0.63137263 0.6104575 ]\n",
            "  [0.24052288 0.24183007 0.24575163 ... 0.71111107 0.6535948  0.6169935 ]\n",
            "  [0.24183007 0.24052288 0.24444444 ... 0.7346406  0.6640523  0.6117647 ]]\n",
            "\n",
            " [[0.530719   0.62614375 0.6653595  ... 0.41960785 0.29281047 0.33594772]\n",
            "  [0.58431375 0.6300654  0.6562092  ... 0.46928108 0.37124184 0.2627451 ]\n",
            "  [0.6026144  0.65751636 0.67058825 ... 0.4836602  0.36078432 0.24313726]\n",
            "  ...\n",
            "  [0.26666668 0.2522876  0.23267974 ... 0.9111111  0.90326804 0.8901961 ]\n",
            "  [0.25882354 0.24575163 0.24052288 ... 0.9006536  0.90718955 0.8862745 ]\n",
            "  [0.25882354 0.24052288 0.24444444 ... 0.9163399  0.8928105  0.8862745 ]]\n",
            "\n",
            " [[0.11633987 0.10196079 0.1267974  ... 0.34248367 0.20130719 0.17908497]\n",
            "  [0.12156863 0.12418301 0.14379086 ... 0.41045752 0.20522876 0.15816994]\n",
            "  [0.13071896 0.13202615 0.14901961 ... 0.4888889  0.26928106 0.19477125]\n",
            "  ...\n",
            "  [0.18169935 0.17254902 0.17254902 ... 0.09281046 0.07058824 0.13986929]\n",
            "  [0.16470589 0.1633987  0.1764706  ... 0.0875817  0.10326798 0.1764706 ]\n",
            "  [0.17908497 0.19477125 0.20392157 ... 0.13333334 0.13725491 0.2535948 ]]]\n",
            "after:------------------------\n",
            "[[[ 78.230095   89.13718   116.96903   ...  45.88496    57.168144\n",
            "    74.84514  ]\n",
            "  [ 86.50443    95.15488   101.548676  ...  41.371685   37.98673\n",
            "    67.32301  ]\n",
            "  [ 92.14603    94.02656    80.48673   ...  56.41593    38.362835\n",
            "    50.022125 ]\n",
            "  ...\n",
            "  [ 41.74779    39.491154   38.362835  ... 195.19914   134.26993\n",
            "    81.238945 ]\n",
            "  [ 40.99558    39.86726    38.73894   ... 159.84515   148.93806\n",
            "    96.283195 ]\n",
            "  [ 40.619473   40.243366   38.73894   ... 108.31859   157.2124\n",
            "   127.876114 ]]\n",
            "\n",
            " [[ 37.063957   75.23983    92.65989   ...  67.827034   45.959305\n",
            "    44.106106 ]\n",
            "  [ 47.8125     86.72965    92.65989   ...  85.24709    60.414246\n",
            "    56.33721  ]\n",
            "  [ 56.70785    90.80669    91.547966  ... 101.92587    66.344475\n",
            "    60.414246 ]\n",
            "  ...\n",
            "  [  5.5595927  63.37936   149.36774   ... 244.99275   229.05524\n",
            "   217.93605  ]\n",
            "  [  5.1889534  66.344475  152.70349   ... 129.3532    132.68895\n",
            "   134.54216  ]\n",
            "  [  3.7063954  69.68024   153.44478   ...  64.49128    90.43605\n",
            "   126.75872  ]]\n",
            "\n",
            " [[ 80.56318    49.038456   51.49038   ...  95.975266   92.122246\n",
            "    92.8228   ]\n",
            "  [ 63.04945    57.79533    51.840656  ...  92.122246   91.77197\n",
            "    93.523346 ]\n",
            "  [ 55.693676   51.49038    53.59203   ...  93.523346   90.37087\n",
            "    91.4217   ]\n",
            "  ...\n",
            "  [108.23488   103.68131   105.08241   ... 166.3805    140.46016\n",
            "   123.29669  ]\n",
            "  [108.2349    108.58517   110.33655   ... 173.73627   135.55632\n",
            "   121.89559  ]\n",
            "  [110.68681   111.03708   111.737625  ... 176.18817    76.71016\n",
            "    71.80631  ]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 30.639532   50.901157   86.97674   ... 179.88371   182.35463\n",
            "   170.98837  ]\n",
            "  [ 43.982555   79.56395   105.26162   ... 177.90698   169.50581\n",
            "   169.01163  ]\n",
            "  [ 44.47674    90.43604    97.84883   ... 179.88371   159.6221\n",
            "   159.6221   ]\n",
            "  ...\n",
            "  [ 46.94767    47.936043   49.418602  ... 167.03488   196.19188\n",
            "   188.28485  ]\n",
            "  [ 48.43023    48.924416   50.40697   ... 226.33717   204.59302\n",
            "   190.75581  ]\n",
            "  [ 48.924416   48.43023    49.912785  ... 235.23257   208.54651\n",
            "   188.77907  ]]\n",
            "\n",
            " [[123.86808   151.77661   163.2459    ...  91.37182    54.28786\n",
            "    66.90405  ]\n",
            "  [139.54274   152.92355   160.56973   ... 105.89957    77.226395\n",
            "    45.49476  ]\n",
            "  [144.89507   160.95204   164.77513   ... 110.104965   74.16792\n",
            "    39.76012  ]\n",
            "  ...\n",
            "  [ 46.641685   42.436287   36.70165   ... 235.11995   232.82611\n",
            "   229.003    ]\n",
            "  [ 44.34783    40.52474    38.995502  ... 232.06148   233.97302\n",
            "   227.85608  ]\n",
            "  [ 44.34783    38.995502   40.14243   ... 236.64919   229.76764\n",
            "   227.85608  ]]\n",
            "\n",
            " [[ 20.218445   15.67961    23.519417  ...  91.60194    47.03883\n",
            "    40.02427  ]\n",
            "  [ 21.868929   22.694172   28.883493  ... 113.05824    48.276695\n",
            "    33.42233  ]\n",
            "  [ 24.75728    25.169903   30.53398   ... 137.81552    68.49514\n",
            "    44.975723 ]\n",
            "  ...\n",
            "  [ 40.84951    37.961163   37.961163  ...  12.791262    5.7766995\n",
            "    27.64563  ]\n",
            "  [ 35.485435   35.072815   39.199028  ...  11.140777   16.092232\n",
            "    39.199028 ]\n",
            "  [ 40.02427    44.975723   47.864075  ...  25.582523   26.820387\n",
            "    63.543686 ]]]\n",
            "(1560, 50, 37)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "UZ_nh_V6QM-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "eETODKOSbU0f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode labels\n",
        "print(len(y_train))\n",
        "print(len(y_test))\n",
        "print(f\"Original unique labels: {np.unique(y_train)}\")\n",
        "\n",
        "le = LabelEncoder()\n",
        "y_train = le.fit_transform(y_train)\n",
        "print(\"after---------------------\")\n",
        "# print(y_train)\n",
        "y_test = le.transform(y_test)\n",
        "print(y_test)\n",
        "print(f\"Original unique labels: {np.unique(y_train)}\")\n",
        "print(len(y_train))\n",
        "print(len(y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGnu1SSwQO0v",
        "outputId": "d910b170-f0dd-4026-9366-120df9d41f29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1248\n",
            "312\n",
            "Original unique labels: [ 0  1  2  3  4  5  6  7  8  9 10 11]\n",
            "after---------------------\n",
            "[ 3  1  3 11  1  3  5  2  4  2  5  2 11  0  3  3  1  1  0  5  3  3  3 10\n",
            " 11  3  3  8  1  1  2  6  3  2  3  3  9  3 10  3  0  1  1 11  5  3  3  3\n",
            "  3  3  1  3  8  1  3  4  1  1  8  2  7  3  3  9  4  1  2  2  3  3  3 11\n",
            "  5  3  1  3  3  8  4  2  4  3  2  4  1 11  1 11 11  1  3  3  1 11 11 11\n",
            "  2  4  3  3  4  5  2  3  3  3  9  2  4  3  1  0  3  3  3  3  1 10  4  4\n",
            "  1  7  0  1 11  3 10 10  3  3  1  6  7 11  7 11  1 11  3  5  3  3  6  3\n",
            "  1  7  1  9  5  3  5  7  4  3  8  1  3  2 11  1  9  3  1  3 11  1  3 11\n",
            "  3  2  3  3  3 11  3  1 11  8  1  3  2  3  3  1  8  0 11 11  1  5  7  3\n",
            "  3 11  1  1  4  8  3  1  3  3  3  3  2  3  2  3  2  3 11  2  3  3  3 11\n",
            " 11  5  5  4  3  3  0  3  3 11  1  3  8  2  3  7  8  3  3 11  1  3  9  6\n",
            "  3  7  1  4  3  2  1 11  3  5  1  4  4  1  3  1  2  1  2  4  6  1  1  1\n",
            "  8  3 11  6  3  3  1  3  1  6  3  0  3  7  0  1  3  7  8 11  3  1  4  4\n",
            "  3 10 11  5  3  3  1  9  1  3  7  3  3  0  0  3  1  3  4  9  2 10 11  3]\n",
            "Original unique labels: [ 0  1  2  3  4  5  6  7  8  9 10 11]\n",
            "1248\n",
            "312\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "\n",
        "def create_cnn_model(input_shape):\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(len(target_names), activation='softmax'))\n",
        "\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "cnn_model = create_cnn_model((50, 37, 1))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "US9GFxb9b1z4",
        "outputId": "0c8ac506-d52b-44ca-a9eb-609ce91bb646"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_cnn_model_two(input_shape):\n",
        "    model = Sequential()\n",
        "\n",
        "    # Convolutional Block 1\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    # Convolutional Block 2\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    # Convolutional Block 3\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    # Additional Convolutional Block 4, with padding and smaller kernel size\n",
        "    model.add(Conv2D(256, (2, 2), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())  # Batch normalization\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
        "\n",
        "    # Flatten and Dense Layers\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(len(target_names), activation='softmax'))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "cnn_model_two = create_cnn_model_two((50, 37, 1))\n"
      ],
      "metadata": {
        "id": "ZtnPvseRdqff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_cnn_model_three(input_shape):\n",
        "    model = Sequential()\n",
        "\n",
        "    # First convolutional block\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu'))  # Added another Conv2D layer\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    # Second convolutional block\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu'))  # Added another Conv2D layer\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    # Third convolutional block\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu'))  # Added another Conv2D layer\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    # Fourth convolutional block\n",
        "    model.add(Conv2D(256, (1, 1), activation='relu'))\n",
        "    model.add(Conv2D(256, (1, 1), activation='relu'))  # Added another Conv2D layer\n",
        "    # model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    # Flatten the output from the convolutional blocks\n",
        "    model.add(Flatten())\n",
        "\n",
        "    # Fully connected layers\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(len(target_names), activation='softmax'))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "cnn_model_three = create_cnn_model_three((50, 37, 1))\n"
      ],
      "metadata": {
        "id": "Z1_ri3WNewyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape data for CNN input\n",
        "X_train_cnn = X_train.reshape((X_train.shape[0], 50, 37, 1))\n",
        "X_test_cnn = X_test.reshape((X_test.shape[0], 50, 37, 1))\n",
        "\n",
        "# Train the model\n",
        "cnn_model.fit(X_train_cnn, y_train, epochs=20, batch_size=32, validation_split=0.1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5vC_a2ab8ty",
        "outputId": "76f57b4c-da57-4edd-a5d2-784c68251b9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 189ms/step - accuracy: 0.1972 - loss: 7.0414 - val_accuracy: 0.3520 - val_loss: 2.0868\n",
            "Epoch 2/20\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 69ms/step - accuracy: 0.2938 - loss: 2.2264 - val_accuracy: 0.3920 - val_loss: 1.9966\n",
            "Epoch 3/20\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 70ms/step - accuracy: 0.3438 - loss: 2.0394 - val_accuracy: 0.3680 - val_loss: 1.8203\n",
            "Epoch 4/20\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 98ms/step - accuracy: 0.3719 - loss: 1.9574 - val_accuracy: 0.4240 - val_loss: 1.6634\n",
            "Epoch 5/20\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 0.4306 - loss: 1.8209 - val_accuracy: 0.5040 - val_loss: 1.5613\n",
            "Epoch 6/20\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 69ms/step - accuracy: 0.4162 - loss: 1.7952 - val_accuracy: 0.4960 - val_loss: 1.5614\n",
            "Epoch 7/20\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 70ms/step - accuracy: 0.4988 - loss: 1.6347 - val_accuracy: 0.6640 - val_loss: 1.2223\n",
            "Epoch 8/20\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - accuracy: 0.5433 - loss: 1.4146 - val_accuracy: 0.6880 - val_loss: 1.1293\n",
            "Epoch 9/20\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 0.5838 - loss: 1.2341 - val_accuracy: 0.7600 - val_loss: 1.0435\n",
            "Epoch 10/20\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 70ms/step - accuracy: 0.6506 - loss: 1.1200 - val_accuracy: 0.7440 - val_loss: 0.9313\n",
            "Epoch 11/20\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 71ms/step - accuracy: 0.6493 - loss: 1.0131 - val_accuracy: 0.6880 - val_loss: 1.0409\n",
            "Epoch 12/20\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - accuracy: 0.7116 - loss: 0.8355 - val_accuracy: 0.8160 - val_loss: 0.7690\n",
            "Epoch 13/20\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - accuracy: 0.7552 - loss: 0.7347 - val_accuracy: 0.8240 - val_loss: 0.8003\n",
            "Epoch 14/20\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 69ms/step - accuracy: 0.7532 - loss: 0.7269 - val_accuracy: 0.7920 - val_loss: 0.7824\n",
            "Epoch 15/20\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 0.8004 - loss: 0.6126 - val_accuracy: 0.8240 - val_loss: 0.6566\n",
            "Epoch 16/20\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 91ms/step - accuracy: 0.8370 - loss: 0.5151 - val_accuracy: 0.8160 - val_loss: 0.6931\n",
            "Epoch 17/20\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - accuracy: 0.8369 - loss: 0.4878 - val_accuracy: 0.8320 - val_loss: 0.6226\n",
            "Epoch 18/20\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 69ms/step - accuracy: 0.8785 - loss: 0.3949 - val_accuracy: 0.8560 - val_loss: 0.6358\n",
            "Epoch 19/20\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 70ms/step - accuracy: 0.8960 - loss: 0.3185 - val_accuracy: 0.8080 - val_loss: 0.8359\n",
            "Epoch 20/20\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - accuracy: 0.9036 - loss: 0.3164 - val_accuracy: 0.8400 - val_loss: 0.7989\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7d83a34d4fd0>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "cnn_model_two.fit(X_train_cnn, y_train, epochs=20, batch_size=32, validation_split=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "riZoA73CfagX",
        "outputId": "5f32ccaf-8bc3-42d6-9cdc-78ab44ff8601"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 170ms/step - accuracy: 0.2585 - loss: 2.8671 - val_accuracy: 0.3520 - val_loss: 3.6921\n",
            "Epoch 2/20\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 135ms/step - accuracy: 0.2927 - loss: 2.2176 - val_accuracy: 0.3520 - val_loss: 3.7951\n",
            "Epoch 3/20\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 155ms/step - accuracy: 0.3029 - loss: 2.2330 - val_accuracy: 0.3520 - val_loss: 2.2168\n",
            "Epoch 4/20\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 153ms/step - accuracy: 0.3730 - loss: 2.1175 - val_accuracy: 0.3200 - val_loss: 2.0788\n",
            "Epoch 5/20\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 122ms/step - accuracy: 0.3740 - loss: 2.0554 - val_accuracy: 0.3840 - val_loss: 2.0501\n",
            "Epoch 6/20\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 173ms/step - accuracy: 0.3583 - loss: 2.0965 - val_accuracy: 0.3360 - val_loss: 4.0963\n",
            "Epoch 7/20\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 122ms/step - accuracy: 0.3833 - loss: 2.0794 - val_accuracy: 0.1600 - val_loss: 5.3957\n",
            "Epoch 8/20\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 163ms/step - accuracy: 0.3852 - loss: 2.0358 - val_accuracy: 0.0560 - val_loss: 11.7920\n",
            "Epoch 9/20\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 122ms/step - accuracy: 0.4259 - loss: 1.8298 - val_accuracy: 0.0560 - val_loss: 10.6927\n",
            "Epoch 10/20\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 156ms/step - accuracy: 0.4648 - loss: 1.6550 - val_accuracy: 0.0560 - val_loss: 15.4603\n",
            "Epoch 11/20\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 120ms/step - accuracy: 0.4926 - loss: 1.5796 - val_accuracy: 0.0880 - val_loss: 8.1942\n",
            "Epoch 12/20\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 169ms/step - accuracy: 0.5100 - loss: 1.4609 - val_accuracy: 0.0960 - val_loss: 8.9537\n",
            "Epoch 13/20\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 121ms/step - accuracy: 0.6078 - loss: 1.2315 - val_accuracy: 0.4560 - val_loss: 2.4197\n",
            "Epoch 14/20\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 122ms/step - accuracy: 0.5795 - loss: 1.2928 - val_accuracy: 0.3040 - val_loss: 5.8436\n",
            "Epoch 15/20\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 157ms/step - accuracy: 0.6346 - loss: 1.0524 - val_accuracy: 0.5280 - val_loss: 1.4824\n",
            "Epoch 16/20\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 121ms/step - accuracy: 0.6465 - loss: 1.0744 - val_accuracy: 0.6400 - val_loss: 1.2753\n",
            "Epoch 17/20\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 145ms/step - accuracy: 0.7184 - loss: 0.8322 - val_accuracy: 0.6480 - val_loss: 1.1535\n",
            "Epoch 18/20\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 120ms/step - accuracy: 0.6843 - loss: 0.8563 - val_accuracy: 0.7840 - val_loss: 0.6930\n",
            "Epoch 19/20\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 169ms/step - accuracy: 0.7163 - loss: 0.8414 - val_accuracy: 0.5200 - val_loss: 2.4134\n",
            "Epoch 20/20\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 121ms/step - accuracy: 0.7805 - loss: 0.6214 - val_accuracy: 0.7520 - val_loss: 0.9189\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7d83a32095a0>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "cnn_model_three.fit(X_train_cnn, y_train, epochs=20, batch_size=32, validation_split=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUaxHPMAfaRr",
        "outputId": "8fad1956-e1ec-460e-8fa4-b3e95a8bc6d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 184ms/step - accuracy: 0.2685 - loss: 2.5305 - val_accuracy: 0.3520 - val_loss: 2.0774\n",
            "Epoch 2/20\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 181ms/step - accuracy: 0.3596 - loss: 2.0762 - val_accuracy: 0.3520 - val_loss: 1.9167\n",
            "Epoch 3/20\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 228ms/step - accuracy: 0.3694 - loss: 1.9597 - val_accuracy: 0.4240 - val_loss: 1.8049\n",
            "Epoch 4/20\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 181ms/step - accuracy: 0.4437 - loss: 1.7550 - val_accuracy: 0.4640 - val_loss: 1.7449\n",
            "Epoch 5/20\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 176ms/step - accuracy: 0.4495 - loss: 1.6494 - val_accuracy: 0.5680 - val_loss: 1.3112\n",
            "Epoch 6/20\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 222ms/step - accuracy: 0.5186 - loss: 1.4732 - val_accuracy: 0.6000 - val_loss: 1.2798\n",
            "Epoch 7/20\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 182ms/step - accuracy: 0.5964 - loss: 1.2680 - val_accuracy: 0.6240 - val_loss: 1.1537\n",
            "Epoch 8/20\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 177ms/step - accuracy: 0.5927 - loss: 1.2669 - val_accuracy: 0.6880 - val_loss: 1.0543\n",
            "Epoch 9/20\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 225ms/step - accuracy: 0.6956 - loss: 0.9090 - val_accuracy: 0.7120 - val_loss: 0.9324\n",
            "Epoch 10/20\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 182ms/step - accuracy: 0.7094 - loss: 0.8519 - val_accuracy: 0.7040 - val_loss: 1.0390\n",
            "Epoch 11/20\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 179ms/step - accuracy: 0.7952 - loss: 0.6260 - val_accuracy: 0.7920 - val_loss: 0.7572\n",
            "Epoch 12/20\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 206ms/step - accuracy: 0.8333 - loss: 0.5489 - val_accuracy: 0.7440 - val_loss: 1.0778\n",
            "Epoch 13/20\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 226ms/step - accuracy: 0.7827 - loss: 0.7507 - val_accuracy: 0.7440 - val_loss: 0.9633\n",
            "Epoch 14/20\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 177ms/step - accuracy: 0.8370 - loss: 0.5398 - val_accuracy: 0.7840 - val_loss: 0.8996\n",
            "Epoch 15/20\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 179ms/step - accuracy: 0.8461 - loss: 0.4574 - val_accuracy: 0.8320 - val_loss: 0.7605\n",
            "Epoch 16/20\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 230ms/step - accuracy: 0.9113 - loss: 0.2858 - val_accuracy: 0.8080 - val_loss: 0.7420\n",
            "Epoch 17/20\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 175ms/step - accuracy: 0.9134 - loss: 0.2760 - val_accuracy: 0.7440 - val_loss: 1.1873\n",
            "Epoch 18/20\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 179ms/step - accuracy: 0.8896 - loss: 0.3662 - val_accuracy: 0.7760 - val_loss: 0.9756\n",
            "Epoch 19/20\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 190ms/step - accuracy: 0.9337 - loss: 0.1933 - val_accuracy: 0.7840 - val_loss: 0.8470\n",
            "Epoch 20/20\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 225ms/step - accuracy: 0.9656 - loss: 0.1604 - val_accuracy: 0.8160 - val_loss: 0.7851\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7d83962bebf0>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    }
  ]
}